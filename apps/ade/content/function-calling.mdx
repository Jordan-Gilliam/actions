---
title: "Function Calling"
group: "Callers"
groupOrder: 100
---

#### LLM Function Calling

# Function Calling

<Warning>
Please read the [Action Calling](/action-calling) documentation first. Function calling builds on top of action calling and you still want to familiarize yourself with the powerful features in action calling.
</Warning>

## Calling Functions

To call functions, pass your action registry to the `setupFunctionCalling` function. This will return an object with a `functions` and `chooseFunction` property.

Send the `functions` property to the LLM.

Send the returned `function_call` to the `functionCallHandler` function.

Done! ðŸŽŠ

```typescript:index.ts
import { setupFunctionCalling } from "ai-actions"
import OpenAI from "openai"

const openai = new OpenAI()

async function invokeActions(userMessage: string) {
  const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
    {
      role: "user",
      content: userMessage,
    },
  ]

  // setup the function calling
  const { functionCallHandler, functions } = setupFunctionCalling(ActionsRegistry, {}) <|highlight|>

  // call the LLM with the functions
  const responseMessage = await openai.chat.completions.create({
    model: "gpt-3.5-turbo-1106",
    messages, 
    functions, // pass the functions <|highlight|>
  })

  // get the function call the LLM made
  const choice = responseMessage.choices[0]
  if (!choice || !choice.message.function_call) return

  // pass the function call to the handler
  const { results, functionCallMessage } = await functionCallHandler( <|highlight|>
    choice.message.function_call <|highlight|>
  ) <|highlight|>

  // a typesafe array of results from the handlers
  console.log(results)

  // append the assistant message to the messages
  messages.push(choice.message)
  
  // append the function call message to the messages
  messages.push(functionCallMessage) <|highlight|>

  // call the LLM again with the handler outputs
  const secondResponse = await openai.chat.completions.create({
    model: "gpt-3.5-turbo-0125",
    messages, 
  })

  // log the final response
  console.log(secondResponse.choices[0]?.message.content)
}

invokeActions("What is the stock price for MSFT?")
```

## Few Shot Function Calls

Few shotting is a technique that allows you to teach the LLM in context by providing examples. 

A common error is providing examples that don't match the schemas of the function. This problem is solved by using the `createFewShotFunctionCallMessages` function.

It will force you to provide type-safe arguments and responses that match the schemas of the function.

```typescript:index.ts
const { functionCallHandler, functions, createFewShotFunctionCallMessages } = setupFunctionCalling(ActionsRegistry, {})

const fewShotMessages: OpenAI.Chat.ChatCompletionMessageParam[] = createFewShotFunctionCallMessages([ // pass the few shot function calls to the handler <|highlight|>
  { <|highlight|>
    userMessageContent: "What is the stock price for MSFT?", <|highlight|>
    function_call: { <|highlight|>
      name: "getStockPrice", <|highlight|>
      arguments: { <|highlight|>
        symbol: "MSFT", <|highlight|>
      }, <|highlight|>
      response: { <|highlight|>
        price: 123, <|highlight|>
      } <|highlight|>
    }, <|highlight|>
    assistantMessageContent: "The stock price for MSFT is $123", <|highlight|>
  }, <|highlight|>
]) <|highlight|>

// call the LLM with the functions
const responseMessage = await openai.chat.completions.create({
  model: "gpt-3.5-turbo-1106",
  messages: [
    ...fewShotMessages,
    {
      role: "user",
      content: "What is the stock price for AAPL?",
    }
  ],
  functions,
})
```

### Inferring Few Shot

You can also use the `inferFewShotFunctionCallMessages` helper to infer the few shot function calls. 

This is useful if you want to define few shot messages outside the scope of `createFewShotFunctionCallMessages`.

```typescript:index.ts
import { inferFewShotFunctionCallMessages } from "ai-actions"

export const fewShotMessages: inferFewShotFunctionCallMessages<
  typeof ActionsRegistry,
  "myActionId" | "myActionId2" // optionally pass in the action ids to infer the few shot function calls for
> = [
  ...
]
```

## Choose Function

If you want the LLM to always call a specific action, use `chooseFunction`.

```typescript:index.ts
// setup the function calling
const { functionCallHandler, functions, chooseFunction } = setupFunctionCalling(ActionsRegistry, {}) <|highlight|>

// call the LLM with the functions
const responseMessage = await openai.chat.completions.create({
  model: "gpt-3.5-turbo-1106",
  messages,
  functions,
  function_call: chooseFunction("getStockPrice"), <|highlight|>
})
```